{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "662da44a",
      "cell_type": "markdown",
      "source": "# Exercise 3\n### Computer Vision, Fall 2025\n#### Name: <font color='blue'>*write your name here*</font>\n---\n**Instructions:**\n- Return the answer in PDF and Jupyter Notebook formats.\n\n- Return latest on<font color='red'> Sunday Sep. 28 at 23.50</font> via Moodle.\n",
      "metadata": {}
    },
    {
      "id": "04ddc4bc-9959-4401-bcdf-67805939d106",
      "cell_type": "markdown",
      "source": "## Ex 3.1. CAMERA MATRIX (4 p)\nPlease find the 3 sets of images provided in the Moodle page of this week's exercise. The three image sets (A,B and C) contain pictures taken of a camera calibration checkerboard pattern with a square size of 3cm.\n\n1. Write a function using built-in OpenCV methods that computes the intrinsic camera calibration matrix and distortion matrix from a given set of calibration images.\n\n2. Apply that function to all three sets of images and observe the results. Based on the results for the intrinsic and distortion matrix, discuss what type of camera or lens was used to capture the different image sets.\n",
      "metadata": {}
    },
    {
      "id": "cc269a8a-57a3-459f-a302-bb36dc894fc0",
      "cell_type": "code",
      "source": "import cv2\nimport numpy as np\nimport os\nimport glob\nfrom matplotlib import pyplot as plt\n\nnp.set_printoptions(suppress=True)\n\n\ndef calibrate(img_path):\n    matrix = None\n    distortion = None\n    # ...\n\n    images = glob.glob(\"{}/*.jpeg\".format(img_path))\n\n    for filename in images:\n        image = cv2.imread(filename)\n        grayColor = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        # ...\n\n    return matrix, distortion\n\n\nprint(\"Images A:\")\nmatrix, distortion = calibrate(\"images_A\")\nprint(matrix)\nprint(distortion)\nprint()\n\nprint(\"Images B:\")\nmatrix, distortion = calibrate(\"images_B\")\nprint(matrix)\nprint(distortion)\nprint()\n\nprint(\"Images C:\")\nmatrix, distortion = calibrate(\"images_C\")\nprint(matrix)\nprint(distortion)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3a2c660e-8752-4c6a-afe2-077b01186e71",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5dfdf103-ef14-4321-90dd-ee49c3ed3073",
      "cell_type": "markdown",
      "source": "## Ex 3.2. HOUGH TRANSFORM (4 p)\n1. Ask ChatGPT to explain the main points about Hough Transform using the key word \"Hough Transform\". Analyse the answer by reflecting it to the course material related to Hough Transform: Were all main points in the course material addressed? if no, please shortly conclude the answers of ChatGPT and our course materials regarding the Hough Transform, and list the differences of answers between our course material and ChatGPT.\n2. We provided you example images from the Berkeley Segmentation Dataset. Implement the Hough Transform (the most basic version) for line detection by yourself (You may only use the openCV function to check if your solution is correct). Instead of using the default parameters, customize the parameters (e.g., resolution of the parameter space, threshold values for line detection, minimum line length, maximum line gap) to optimize edge detection for the given set of images. Report your observations: which parameters influenced which behaviour in the output? Also report which parameter configuration resembles closest an object segmentation in the test images.\n",
      "metadata": {}
    },
    {
      "id": "f7107da6-a27d-4117-a0f1-20aa5fd364c8",
      "cell_type": "code",
      "source": "#2)\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef apply_hough_transform(image):\n    ...\n\n\nimages = glob.glob(\"segmentation_images/*.jpg\")\n\nfor filename in images:\n    image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n    ...",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "61aab545-be21-4abf-81a2-559d0fccb300",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}